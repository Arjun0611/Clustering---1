{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d1fd02-1b32-4990-9d61-48cfee184098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.\n",
    "\n",
    "# K-Means Clustering\n",
    "    # Approach: Partition data into k clusters based on centroids.\n",
    "    # Assumption: Assumes spherical-shaped clusters of approximately equal sizes.\n",
    "# Hierarchical Clustering:\n",
    "    # Approach: Builds a hierarchy of clusters, either agglomerative or divisive\n",
    "    # Assumption: No fixed number of clusters, captures nested structures.\n",
    "# DBSCAN:\n",
    "    # Approach: Forms clusters based on dense regions in data space.\n",
    "    # Assumption: Assumes clusters as dense, separated areas in feature space.\n",
    "# Agglomerative Hierarchical Clustering:\n",
    "    # Approach: Starts with individual data points and merges them hierarchically.\n",
    "    # Assumption: No fixed number of clusters, creates a tree-like structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f00e1c9-cf65-4410-b801-e9c16dbdd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.\n",
    "\n",
    "# K Means Clustering\n",
    "\n",
    "# An algorithm that divides a dataset into k clusters, where each observation belongs to the cluster with th nearest mean.\n",
    "\n",
    "# Working\n",
    "    # Randomly select k initial cluster centrids.\n",
    "    # Assign each data point to the cluster with the nearest centroid.\n",
    "    # Recalculate cluster centroids as the mean of data points in each cluster.\n",
    "    # Iteratively repeat the assignment and update steps until convergence.\n",
    "# Objective: Minimize the sum of squared distances between data points and their respective cluster centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211c8705-31ae-445c-b118-fb8ca3dbc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.\n",
    "\n",
    "# Advantages\n",
    "    # Computationally efficient and easy to implement.\n",
    "    # Scales well to large datasets.\n",
    "    # Converges to a local optimum, providing a clear result.\n",
    "\n",
    "# Limitations\n",
    "    # Struggles with non-spherical or unevenly sized clusters.\n",
    "    # Results may vary based on initial centroid selection.\n",
    "    # The number of clusters needs to be specified beforehand.\n",
    "    # Influenced by outliers, affecting cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba01d83a-8178-42ba-b8a7-ee3db6fcb16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4.\n",
    "\n",
    "# Optimal Number of clusters\n",
    "\n",
    "# Elbow Method: \n",
    "    # Plot the sum of squared distances for different values of k.\n",
    "    # Identify the \"elbow\" point where the rate of decrease slows.\n",
    "    # The point where adding more clusters provides diminishing returns.\n",
    "\n",
    "# Silhouette Score:\n",
    "    # Measure how well-separated clusters are using silhouette coefficients.\n",
    "    # Choose k with the highest average silhouette score.\n",
    "    # Maximizes cohesion within clusters and separation between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a907e40c-acb2-4ba0-9e9e-14165e66b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5.\n",
    "\n",
    "# Image Compression:\n",
    "    # Application: Reduce image size by grouping similar pixels into clusters.\n",
    "    # Usage: Minimize data storage and transmission requirements.\n",
    "# Customer Segmentation:\n",
    "    # Application: Group customers based on behaviour and preferences.\n",
    "    # Usage: Tailor marketing strategies and services to specific segments.\n",
    "# Document Clustering:\n",
    "    # Application: Group documents with similar content.\n",
    "    # Usage: Organize large document collections for efficient retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50182305-f3d4-4ab8-bccc-127b9259a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6.\n",
    "\n",
    "# Cluster Centers:\n",
    "    # Interpretation: Mean values of features for each cluster.\n",
    "    # Insights: Identify characteristic properties of each cluster.\n",
    "\n",
    "# Cluster Assignments:\n",
    "    # Interpretation: Assignment of data points to specific clusters.\n",
    "    # Insights: Understand which data points share similar characteristics.\n",
    "\n",
    "# Inertia (Within-Cluster Sum of Squares):\n",
    "    # Interpretation: Measure of cluster tightness.\n",
    "    # Insights: Lower inertia indicates more compact clusters.\n",
    "\n",
    "# Visualizations:\n",
    "    # Interpretation: Plotting data points and centroids.\n",
    "    # Insights: Visualize spatial distribution and relationships between clusters.\n",
    "\n",
    "# Comparisons:\n",
    "    # Interpretation: Compare cluster properties and sizes.\n",
    "    # Insights: Identify patterns and variations between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b32db2-b699-4a7b-8e58-4a0fbeffab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7.\n",
    "\n",
    "# Sensitivity to Initial Centroids:\n",
    "    # Challenge: Results may vary based on initial centroid selection.\n",
    "    # Address: Run multiple initializations and choose the best result.\n",
    "\n",
    "# Determining Optimal K:\n",
    "    # Challenge: Predefining the number of clusters (k).\n",
    "    # Address: Use techniques like the elbow method or silhouette score.\n",
    "\n",
    "# Handling Non-Spherical Clusters:\n",
    "    # Challenge: K-means assumes spherical clusters.\n",
    "    # Address: Consider using algorithms designed for non-spherical clusters.\n",
    "\n",
    "# Outliers Impacting Results:\n",
    "    # Challenge: Sensitive to outliers affecting cluster assignments.\n",
    "    # Address: Consider preprocessing or using robust variants of K-means.\n",
    "\n",
    "# Scalability with Large Datasets:\n",
    "    # Challenge: Computationally expensive for large datasets.\n",
    "    # Address: Use scalable variants or perform dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc14d7-64f6-4e0d-b1ff-f6ffbf8a5ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
